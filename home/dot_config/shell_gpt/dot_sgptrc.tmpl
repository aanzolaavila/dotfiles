# API key, also it is possible to define OPENAI_API_KEY env.
# === Already setup by ZSH config ===
# OPENAI_API_KEY=your_api_key

# Base URL of the backend server. If "default" URL will be resolved based on --model.
API_BASE_URL=default

# Max amount of cached message per chat session.
CHAT_CACHE_LENGTH=100

# Chat cache folder.
CHAT_CACHE_PATH=/tmp/shell_gpt/chat_cache

# Request cache length (amount).
CACHE_LENGTH=100

# Request cache folder.
CACHE_PATH=/tmp/shell_gpt/cache

# Request timeout in seconds.
REQUEST_TIMEOUT=60

# Default OpenAI model to use.
DEFAULT_MODEL=gpt-3.5-turbo-0125

# Default color for shell and code completions.
DEFAULT_COLOR=magenta

# When in --shell mode, default to "Y" for no input.
DEFAULT_EXECUTE_SHELL_CMD=false

# Disable streaming of responses
DISABLE_STREAMING=false

# The pygment theme to view markdown (default/describe role).
CODE_THEME=default

# Path to a directory with functions.
OPENAI_FUNCTIONS_PATH={{ .chezmoi.homeDir -}}/.config/shell_gpt/functions

# Print output of functions when LLM uses them.
SHOW_FUNCTIONS_OUTPUT=false

# Allows LLM to use functions.
OPENAI_USE_FUNCTIONS=true

# Where to store the roles
ROLE_STORAGE_PATH={{ .chezmoi.homeDir -}}/.config/shell_gpt/roles

PRETTIFY_MARKDOWN=true
USE_LITELLM=false
